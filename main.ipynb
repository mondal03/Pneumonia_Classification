{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing mac specific dotfiles\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def rem_macfiles(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == \".DS_Store\":\n",
    "                os.remove(os.path.join(root, file))\n",
    "\n",
    "rem_macfiles(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import splitfolders\n",
    "from glob import glob\n",
    "# from tqdm import tqdm, trange\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from numba import njit, jit\n",
    "from natsort import natsorted\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#PIL\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "#random\n",
    "from random import sample\n",
    "\n",
    "#open cv\n",
    "import cv2\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#scipy\n",
    "from scipy import stats \n",
    "\n",
    "#pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#timm\n",
    "import timm\n",
    "import timm.optim\n",
    "import timm.scheduler\n",
    "from timm.data import ImageDataset, create_dataset, create_loader\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Apple Silicon or CUDA for enhanced training\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visilize one image\n",
    "\n",
    "paths = glob('./data/train/**/**')\n",
    "\n",
    "Image.open(paths[0]).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining image tranformations\n",
    "\n",
    "img_size_train = 256            ## values to be selected by looking at the huggingface page of each model\n",
    "\n",
    "img_size_test = 320\n",
    "\n",
    "transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize(size=(img_size_train, img_size_train), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(size=(img_size_test, img_size_test), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing the data\n",
    "\n",
    "train_path = './data/train/'\n",
    "\n",
    "dataset = ImageDataset(train_path, transform=transform[\"train\"])\n",
    "id2label = natsorted(os.listdir('./data/train/'))\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = glob('./data/train/**/**')\n",
    "y = natsorted(y)\n",
    "y = [os.path.basename(os.path.dirname(i)) for i in y]\n",
    "\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check data count\n",
    "len(paths), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training parameters\n",
    "\n",
    "model_name = 'resnet18'\n",
    "\n",
    "num_epochs = 15\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 4\n",
    "num_accumulate = 4\n",
    "num_classes = len(id2label)\n",
    "\n",
    "## Cross validarion configuration\n",
    "k_splits = 5\n",
    "metric = evaluate.load(\"f1\", additional_keys=[\"accuracy\", \"precision\", \"recall\", \"support\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_scores = []\n",
    "\n",
    "!rm -rf first_model\n",
    "!mkdir first_model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_splits, shuffle=True)\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(dataset, y)):\n",
    "    \n",
    "    # display fold number\n",
    "    print(f\"\\nFold: {fold+1} / {k_splits}\")\n",
    "\n",
    "    # load model\n",
    "    model = timm.create_model(model_name=model_name, pretrained=True, num_classes=num_classes).to(device)\n",
    "\n",
    "    # optimizer and sceduler\n",
    "    optimizer = timm.optim.create_optimizer_v2(model, opt=\"AdamW\", lr=1e-3)\n",
    "    scheduler = timm.scheduler.create_scheduler_v2(optimizer, num_epochs=num_epochs)[0]\n",
    "\n",
    "    # split main dataset into train and val set with kfold\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "    # dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=eval_batch_size, shuffle=True)\n",
    "\n",
    "    # Reset Model Info\n",
    "    info = {\n",
    "        \"metric_train\": {\"f1\": [], \"accuracy\": [], \"precision\": [], \"recall\": [], \"auc_roc\": []},\n",
    "        \"metric_val\": {\"f1\": [], \"accuracy\": [], \"precision\": [], \"recall\": [], \"auc_roc\": []},\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"best_metric_val\": -np.inf,\n",
    "        \"confusion_matrix\": None,\n",
    "    }\n",
    "    count = 0\n",
    "\n",
    "    # Create a LabelBinarizer object to convert labels to binary class matrix\n",
    "    lb = LabelBinarizer()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_epoch = []\n",
    "        val_loss_epoch = []\n",
    "    \n",
    "        train_preds = []\n",
    "        train_targets = []\n",
    "    \n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "    \n",
    "        num_updates = epoch * len(train_dataloader)\n",
    "\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for idx, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if ((idx + 1) % num_accumulate == 0) or (idx + 1 == len(train_dataloader)):\n",
    "                optimizer.step()\n",
    "                scheduler.step_update(num_updates=num_updates)\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            train_loss_epoch.append(loss.item())\n",
    "            train_preds += logits.argmax(-1).detach().tolist()\n",
    "            train_targets += y.tolist()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch + 1)\n",
    "\n",
    "        # Evaluation loop\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (X, y) in tqdm(val_dataloader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "                val_loss_epoch.append(loss.item())\n",
    "                val_preds += logits.argmax(-1).detach().tolist()\n",
    "                val_targets += y.tolist()\n",
    "\n",
    "\n",
    "        # Convert labels to binary class matrix\n",
    "        train_targets_bin = lb.fit_transform(train_targets)\n",
    "        train_preds_bin = lb.transform(train_preds)\n",
    "\n",
    "        # Convert labels to binary class matrix\n",
    "        val_targets_bin = lb.fit_transform(val_targets)\n",
    "        val_preds_bin = lb.transform(val_preds)\n",
    "                \n",
    "        # Compute evaluation metrics\n",
    "        metric_train = metric.compute(predictions=train_preds, references=train_targets, average=\"macro\")\n",
    "        metric_val = metric.compute(predictions=val_preds, references=val_targets, average=\"macro\")\n",
    "\n",
    "        # Calculate metrics for the training set\n",
    "        precision_train, recall_train, f1_train, support_train = precision_recall_fscore_support(train_targets, train_preds, average='macro')\n",
    "        acc_train = np.sum(np.array(train_preds) == np.array(train_targets)) / len(train_preds)\n",
    "\n",
    "        # Calculate metrics for the validation set\n",
    "        precision_val, recall_val, f1_val, support_val = precision_recall_fscore_support(val_targets, val_preds, average='macro')\n",
    "        acc_val = np.sum(np.array(val_preds) == np.array(val_targets)) / len(val_preds)\n",
    "\n",
    "        info[\"metric_train\"][\"f1\"].append(f1_train)\n",
    "        info[\"metric_train\"][\"precision\"].append(precision_train)\n",
    "        info[\"metric_train\"][\"recall\"].append(recall_train)\n",
    "        info[\"metric_train\"][\"auc_roc\"].append(roc_auc_score(train_targets_bin, train_preds_bin, multi_class='ovo'))\n",
    "        info[\"metric_train\"][\"accuracy\"].append(acc_train)\n",
    "\n",
    "        info[\"metric_val\"][\"f1\"].append(f1_val)\n",
    "        info[\"metric_val\"][\"precision\"].append(precision_val)\n",
    "        info[\"metric_val\"][\"recall\"].append(recall_val)\n",
    "        info[\"metric_val\"][\"auc_roc\"].append(roc_auc_score(val_targets_bin, val_preds_bin, multi_class='ovo'))\n",
    "        info[\"metric_val\"][\"accuracy\"].append(acc_val)\n",
    "        \n",
    "        info[\"train_loss\"].append(np.average(train_loss_epoch))\n",
    "        info[\"val_loss\"].append(np.average(val_loss_epoch))\n",
    "\n",
    "        cm = confusion_matrix(val_targets, val_preds)\n",
    "        info[\"confusion_matrix\"] = cm.tolist()\n",
    "\n",
    "        if metric_val[\"f1\"] > info[\"best_metric_val\"]:\n",
    "            print(\"\\nNew Best Score!\")\n",
    "            info[\"best_metric_val\"] = metric_val[\"f1\"]\n",
    "            torch.save(model, f\"./first_model/checkpoint_fold{fold}.pt\")\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "        print(info)\n",
    "        print(f\"Fold: {fold} | Epoch: {epoch} | Metric: {metric_val['f1']} | Training Loss: {np.average(train_loss_epoch)} | Validation Loss: {np.average(val_loss_epoch)}\\n\")\n",
    "\n",
    "    # save all best metric val\n",
    "    all_eval_scores.append(info[\"best_metric_val\"])\n",
    "\n",
    "print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the labels \n",
    "\n",
    "id2label = natsorted(os.listdir('./data/test/'))\n",
    "if '.DS_Store' in id2label:\n",
    "    id2label.remove('.DS_Store')\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the test data \n",
    "\n",
    "test_paths = natsorted(glob(\"./data/test/**/**\"))\n",
    "test_y = [os.path.basename(os.path.dirname(path)) for path in test_paths]\n",
    "\n",
    "test_paths[:5], test_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert literal classes in y_test to numeric labels\n",
    "\n",
    "label_map = dict(zip(id2label, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]))\n",
    "\n",
    "lables = list(map(lambda x: label_map[x], test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ensemble method\n",
    "pred_all = []\n",
    "\n",
    "for fold in trange(5):\n",
    "\n",
    "    #load model\n",
    "    model = torch.load(f\"./first_model/checkpoint_fold{fold}.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for f in tqdm(test_paths):\n",
    "\n",
    "            #image\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "            transformed = transform[\"test\"](img).unsqueeze(0).to(device)\n",
    "\n",
    "            #cls\n",
    "            cls = model(transformed).argmax(-1).item()\n",
    "            #cls = id2label[cls]\n",
    "\n",
    "            pred.append(cls)\n",
    "\n",
    "    #for ensemble method\n",
    "    pred_all.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble_value\n",
    "sub_ensemble = []\n",
    "\n",
    "#num of fold\n",
    "kfold = 5 #kfold\n",
    "\n",
    "#ensemble\n",
    "for i in trange(len(pred_all[0])):\n",
    "    check = []\n",
    "    \n",
    "    #loop every fold\n",
    "    for j in range(kfold):\n",
    "        check.append(pred_all[j][i])\n",
    "  \n",
    "    cls = stats.mode(check).mode\n",
    "    sub_ensemble.append(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(lables, sub_ensemble)\n",
    "precision_test, recall_test, f1_test, support_test = precision_recall_fscore_support(lables, sub_ensemble, average='macro')\n",
    "print(f'accuracy {acc}')\n",
    "print(f'precision {precision_test}')\n",
    "print(f'recall {recall_test}')\n",
    "print(f'f1-score {f1_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
